# ğŸ§  Hivemind-Prism: Autonomous AI Security Intelligence Platform

[![AWS](https://img.shields.io/badge/AWS-Cloud%20Native-orange?logo=amazon-aws)](https://aws.amazon.com/)
[![Python](https://img.shields.io/badge/Python-3.12-blue?logo=python)](https://www.python.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0-blue?logo=typescript)](https://www.typescriptlang.org/)
[![CDK](https://img.shields.io/badge/AWS%20CDK-IaC-yellow)](https://aws.amazon.com/cdk/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **An autonomous multi-agent system that independently analyzes, synthesizes, and archives security findings through AI-powered agents that negotiate, learn, and adapt.**

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Architecture](#-architecture)
- [Key Features](#-key-features)
- [Agentic Intelligence](#-agentic-intelligence)
- [Quick Start](#-quick-start)
- [Deployment](#-deployment)
- [Project Structure](#-project-structure)
- [Testing](#-testing)
- [Cost Estimation](#-cost-estimation)
- [Documentation](#-documentation)
- [Contributing](#-contributing)

---

## ğŸ¯ Overview

Hivemind-Prism is a **zero-API, event-driven security intelligence platform** that deploys specialized AI agents to autonomously analyze code repositories. Unlike traditional security pipelines, our agents:

- ğŸ¤– **Make Independent Decisions** based on context, not pre-programmed rules
- ğŸ—£ï¸ **Negotiate Conclusions** through multi-agent consensus and voting
- ğŸ“š **Learn from Past Missions** via RAG-powered institutional memory
- ğŸ¯ **Adapt Strategies** based on codebase characteristics
- âœ… **Validate Each Other** through structured challenge protocols

### Why "Agentic"?

Traditional security tools run in rigid pipelines: Tool A â†’ Tool B â†’ Report. Hivemind-Prism agents **reason, debate, and learn** like a security team would:

```
Traditional Pipeline          Agentic Hivemind-Prism
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ Scan Code â”‚               â”‚ Archaeologist discovers context
      â†“                           â†“
â”‚ Run Tools â”‚               â”‚ Strategist plans approach (using past learnings)
      â†“                           â†“
â”‚ Generate Report â”‚         â”‚ Coordinator allocates resources
                                  â†“
                            â”‚ Tools execute in parallel
                                  â†“
                            â”‚ Synthesizer drafts findings
                                  â†“
                            â”‚ Critic challenges findings
                                  â†“
                            â”‚ Agents negotiate via evidence + voting
                                  â†“
                            â”‚ Archivist archives consensus + creates memories
                                  â†“
                            â”‚ System gets smarter for next mission
```

---

## ğŸ—ï¸ Architecture

### High-Level System Flow

```mermaid
graph TB
    subgraph Developer["ğŸ‘¨â€ğŸ’» Developer Workstation"]
        CLI[hivemind-cli]
        Package[source.tar.gz + metadata.json]
        CLI -->|Package & Authenticate| Package
    end
    
    subgraph AWS["â˜ï¸ AWS Cloud VPC"]
        subgraph Ingestion["ğŸ“¥ Ingestion Layer"]
            S3Upload[S3: hivemind-uploads/]
            EventBridge[EventBridge: CodeUploadTrigger]
            Package -->|IAM Auth S3 PutObject| S3Upload
            S3Upload -->|S3 Event| EventBridge
        end
        
        subgraph Orchestration["ğŸ­ Orchestration"]
            StepFunctions[Step Functions: AgenticOrchestrator]
            EventBridge -->|Start Execution| StepFunctions
            
            Phase1[Phase 1: UnpackAndValidate Lambda]
            Phase2[Phase 2: Context Discovery Archaeologist]
            Phase3[Phase 3: Strategic Planning Strategist]
            Phase4[Phase 4: Tool Execution MCP Servers]
            Phase5[Phase 5: Synthesis & Critique]
            Phase6[Phase 6: Archival & Memory]
            
            StepFunctions --> Phase1 --> Phase2 --> Phase3 --> Phase4 --> Phase5 --> Phase6
        end
        
        subgraph Agents["ğŸ¤– Agentic Intelligence Layer"]
            subgraph Tier1["Tier 1: Discovery"]
                Archaeologist[Archaeologist<br/>Context Discovery]
            end
            
            subgraph Tier2["Tier 2: Planning"]
                Strategist[Strategist<br/>MCP Plans]
                Coordinator[Coordinator<br/>Resources]
            end
            
            subgraph Tier3["Tier 3: Synthesis"]
                Synthesizer[Synthesizer<br/>Findings]
                Critic[Critic<br/>Validation]
                Archivist[Archivist<br/>Memory]
            end
            
            Archaeologist --> Strategist
            Strategist --> Coordinator
            Coordinator --> Synthesizer
            Synthesizer --> Critic
            Critic --> Archivist
        end
        
        subgraph Cognitive["ğŸ§  Cognitive Kernel"]
            Bedrock[Amazon Bedrock<br/>Claude Sonnet 4]
            Kendra[Amazon Kendra<br/>RAG Institutional Memory]
            Titan[Titan Embeddings<br/>Semantic Search]
        end
        
        subgraph MCPTools["ğŸ”§ MCP Tool Fleet"]
            Semgrep[Semgrep MCP<br/>Static Analysis]
            Gitleaks[Gitleaks MCP<br/>Secret Detection]
            Trivy[Trivy MCP<br/>Container Scan]
        end
        
        subgraph Storage["ğŸ’¾ Persistence & Memory"]
            DynamoDB[(DynamoDB<br/>FindingsArchive<br/>ToolResultsIndex)]
            S3Artifacts[(S3<br/>Artifacts & Memories)]
            ElastiCache[(ElastiCache<br/>Agent State)]
        end
        
        Archaeologist -.->|Query Context| Kendra
        Strategist -.->|Query Plans| Kendra
        Synthesizer -.->|Query Patterns| Kendra
        
        Archaeologist -.->|Invoke| Bedrock
        Strategist -.->|Invoke| Bedrock
        Synthesizer -.->|Invoke| Bedrock
        Critic -.->|Invoke| Bedrock
        
        Coordinator -->|Launch| Semgrep
        Coordinator -->|Launch| Gitleaks
        Coordinator -->|Launch| Trivy
        
        Semgrep -->|Results| S3Artifacts
        Gitleaks -->|Results| S3Artifacts
        Trivy -->|Results| S3Artifacts
        
        Archivist -->|Write Findings| DynamoDB
        Archivist -->|Create Memories| S3Artifacts
        
        Archaeologist -.->|Update State| ElastiCache
        Strategist -.->|Update State| ElastiCache
        Coordinator -.->|Update State| ElastiCache
    end
    
    style Developer fill:#e1f5ff
    style AWS fill:#fff4e6
    style Agents fill:#f3e5f5
    style Cognitive fill:#e8f5e9
    style MCPTools fill:#fff3e0
    style Storage fill:#fce4ec
```

### Agent Decision Loop

Each agent operates autonomously using this 5-phase cycle:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AGENT DECISION LOOP                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ 1. SENSE                                             â”‚     â”‚
â”‚  â”‚    - Read mission state from ElastiCache             â”‚     â”‚
â”‚  â”‚    - Retrieve relevant context from Kendra           â”‚     â”‚
â”‚  â”‚    - Check peer agent outputs in S3                  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                        â”‚                                      â”‚
â”‚                        â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ 2. THINK (Bedrock Claude Sonnet 4)                   â”‚     â”‚
â”‚  â”‚    - Formulate hypothesis                            â”‚     â”‚
â”‚  â”‚    - Generate action plan                            â”‚     â”‚
â”‚  â”‚    - Consider alternatives                           â”‚     â”‚
â”‚  â”‚    - Estimate confidence                             â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                        â”‚                                      â”‚
â”‚                        â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ 3. DECIDE                                            â”‚     â”‚
â”‚  â”‚    - Select best action based on:                    â”‚     â”‚
â”‚  â”‚      * Past mission outcomes (Kendra)                â”‚     â”‚
â”‚  â”‚      * Resource availability (ElastiCache)           â”‚     â”‚
â”‚  â”‚      * Peer agent consensus                          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                        â”‚                                      â”‚
â”‚                        â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ 4. ACT                                               â”‚     â”‚
â”‚  â”‚    - Execute chosen action                           â”‚     â”‚
â”‚  â”‚    - Write results to designated output              â”‚     â”‚
â”‚  â”‚    - Update agent state in ElastiCache               â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                        â”‚                                      â”‚
â”‚                        â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ 5. REFLECT                                           â”‚     â”‚
â”‚  â”‚    - Evaluate action outcome                         â”‚     â”‚
â”‚  â”‚    - Update confidence scores                        â”‚     â”‚
â”‚  â”‚    - Log decision rationale                          â”‚     â”‚
â”‚  â”‚    - Trigger memory formation if novel               â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Key Features

### ğŸš« Zero API Gateway Architecture
- **No exposed endpoints** - IAM-authenticated S3 uploads only
- **Event-driven** - S3 + EventBridge trigger orchestration
- **Serverless-first** - Lambda functions and Fargate containers

### ğŸ¤– Six Specialized AI Agents

| Agent | Role | Key Capabilities |
|-------|------|------------------|
| **Archaeologist** | Context Discovery | Analyzes code structure, identifies criticality, maps data flows |
| **Strategist** | Strategic Planning | Queries past missions, generates tool execution plans |
| **Coordinator** | Resource Allocation | Schedules parallel MCP invocations, monitors task health |
| **Synthesizer** | Finding Generation | Drafts preliminary findings, enriches with Kendra context |
| **Critic** | Quality Assurance | Challenges findings, validates severity, checks false positives |
| **Archivist** | Memory Formation | Archives consensus findings, creates institutional memories |

### ğŸ”§ MCP Tool Integration

Model Context Protocol servers for security scanning:
- **Semgrep MCP** - Static analysis for vulnerabilities
- **Gitleaks MCP** - Secret detection
- **Trivy MCP** - Container and dependency scanning

### ğŸ“š Institutional Memory (RAG)

- **Amazon Kendra** indexes all past findings, patterns, and policies
- Agents query historical context before making decisions
- System **learns and improves** with each mission
- Memory documents auto-generated after each finding

### ğŸ—³ï¸ Multi-Agent Negotiation

Agents don't just run in sequence - they **debate**:

```
1. Synthesizer proposes: "SQL Injection - CRITICAL"
2. Critic challenges: "Downgrade to HIGH - mitigation present"
3. Both retrieve evidence from Kendra
4. Weighted voting determines consensus
5. Archivist records decision + rationale
```

---

## ğŸ§  Agentic Intelligence

### What Makes This "Agentic"?

| Traditional Tool | Agentic Hivemind-Prism |
|------------------|------------------------|
| Hardcoded rules | LLM-powered reasoning |
| Fixed severity | Contextual analysis |
| One-time scan | Learns from history |
| No false positive filtering | Multi-agent validation |
| Static reports | Evolving knowledge base |

### Decision Making Process

```
Agent receives task
      â”‚
      â”œâ”€> Queries Kendra: "Similar past scenarios?"
      â”‚
      â”œâ”€> Analyzes code context with Claude Sonnet 4
      â”‚
      â”œâ”€> Checks peer agent state in ElastiCache
      â”‚
      â”œâ”€> Generates multiple options with confidence scores
      â”‚
      â”œâ”€> Selects best action based on:
      â”‚   - Historical outcomes
      â”‚   - Current resource availability
      â”‚   - Peer consensus
      â”‚
      â””â”€> Executes + logs decision for future learning
```

---

## ğŸš€ Quick Start

### Prerequisites

- **AWS Account** with Admin access
- **AWS CLI** v2+ configured with credentials
- **Docker** v20+ running
- **Node.js** 18+ and npm
- **Python** 3.12+
- **CDK** v2.0+ (`npm install -g aws-cdk`)

### 1. Clone and Setup

```bash
git clone https://github.com/your-org/hivemind-prism.git
cd hivemind-prism

# Install CDK dependencies
npm install

# Install Python test dependencies
pip install -r requirements-test.txt
```

### 2. Run Tests

```bash
# Run all tests with coverage
pytest tests/ -v --cov=src --cov-report=html

# Expected: 109 passed, 80%+ coverage
```

### 3. Deploy to AWS

```bash
# Set environment variables
export AWS_REGION=us-east-1
export AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

# Run pre-deployment validation
./scripts/validate-pre-deployment.sh

# Create ECR repositories for Docker images
./scripts/create-ecr-repos.sh

# Build and push Docker images (~10-15 minutes)
./scripts/build-and-push-images.sh

# Bootstrap CDK (first time only)
npx cdk bootstrap aws://$AWS_ACCOUNT_ID/$AWS_REGION

# Deploy all stacks (~35-40 minutes)
npx cdk deploy --all --require-approval never
```

### 4. Enable Bedrock Models

âš ï¸ **Manual step required:**

```bash
# 1. Open AWS Console â†’ Amazon Bedrock â†’ Model Access
# 2. Request access to:
#    - Anthropic Claude Sonnet 4
#    - Amazon Titan Embeddings G1 - Text
# 3. Wait for approval (usually instant)
```

### 5. Use the CLI

```bash
# Install CLI tool
pip install ./cli

# Configure CLI
hivemind configure \
  --region us-east-1 \
  --bucket hivemind-uploads-$AWS_ACCOUNT_ID

# Submit code for analysis
hivemind scan ./path/to/repo \
  --repo-name my-service \
  --mission-id scan-$(date +%s)

# Check status
hivemind status scan-1234567890

# Retrieve findings
hivemind findings scan-1234567890 --format json
```

---

## ğŸ“¦ Deployment

### Infrastructure Stacks

The CDK application deploys 6 stacks with clean dependency chain:

```mermaid
graph TD
    Network[ğŸ“¡ NetworkStack<br/>VPC, Subnets, NAT<br/>Security Groups]
    
    Network --> Security
    
    Security[ğŸ” SecurityStack<br/>KMS Keys<br/>IAM Base Roles]
    
    Security --> Storage
    
    Storage[ğŸ’¾ StorageStack<br/>S3 Buckets<br/>DynamoDB Tables<br/>ElastiCache Cluster]
    
    Storage --> Intelligence
    
    Intelligence[ğŸ§  IntelligenceStack<br/>Amazon Kendra Index<br/>Bedrock Access Policies]
    
    Intelligence --> Compute
    
    Compute[âš™ï¸ ComputeStack<br/>ECS Cluster<br/>Agent Task Definitions<br/>Lambda Functions<br/>IAM Execution Roles]
    
    Compute --> Orchestration
    
    Orchestration[ğŸ­ OrchestrationStack<br/>Step Functions<br/>EventBridge Rules<br/>Step Functions IAM Role]
    
    style Network fill:#e1f5ff
    style Security fill:#f3e5f5
    style Storage fill:#fff4e6
    style Intelligence fill:#e8f5e9
    style Compute fill:#fff3e0
    style Orchestration fill:#fce4ec
```

### Resource Summary

| Service | Purpose | Estimated Cost/Month |
|---------|---------|---------------------|
| ECS Fargate | Agent execution | $50-100 |
| Amazon Bedrock | LLM inference | $100-300 |
| Amazon Kendra | RAG retrieval | $810 (1 AZ) |
| Lambda | Event handlers | $5-10 |
| S3 | Artifact storage | $5-20 |
| DynamoDB | Finding storage | $10-25 |
| ElastiCache | State coordination | $15-30 |
| **Total** | | **~$1,000-1,300/month** |

> ğŸ’¡ **Cost Optimization**: Use Kendra Developer Edition ($1.40/hr when running) and scale Fargate tasks to 0.25 vCPU

### Cleanup

```bash
# Destroy all resources
npx cdk destroy --all

# Delete ECR images
./scripts/delete-ecr-repos.sh

# Remove S3 buckets (if not using retention)
aws s3 rb s3://hivemind-uploads-$AWS_ACCOUNT_ID --force
aws s3 rb s3://hivemind-artifacts-$AWS_ACCOUNT_ID --force
```

---

## ğŸ“ Project Structure

```
hivemind-prism/
â”œâ”€â”€ bin/
â”‚   â””â”€â”€ app.ts                      # CDK app entry point
â”œâ”€â”€ infrastructure/
â”‚   â””â”€â”€ stacks/
â”‚       â”œâ”€â”€ network-stack.ts        # VPC, subnets, NAT gateway
â”‚       â”œâ”€â”€ security-stack.ts       # KMS, security groups, IAM base
â”‚       â”œâ”€â”€ storage-stack.ts        # S3, DynamoDB, ElastiCache
â”‚       â”œâ”€â”€ intelligence-stack.ts   # Kendra, Bedrock access
â”‚       â”œâ”€â”€ compute-stack.ts        # ECS, Lambda, agent roles
â”‚       â””â”€â”€ orchestration-stack.ts  # Step Functions, EventBridge
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                     # 6 autonomous agents
â”‚   â”‚   â”œâ”€â”€ archaeologist/
â”‚   â”‚   â”œâ”€â”€ strategist/
â”‚   â”‚   â”œâ”€â”€ coordinator/
â”‚   â”‚   â”œâ”€â”€ synthesizer/
â”‚   â”‚   â”œâ”€â”€ critic/
â”‚   â”‚   â””â”€â”€ archivist/
â”‚   â”œâ”€â”€ lambdas/                    # Event handlers
â”‚   â”‚   â”œâ”€â”€ unpack/
â”‚   â”‚   â”œâ”€â”€ memory_ingestor/
â”‚   â”‚   â””â”€â”€ failure_handler/
â”‚   â”œâ”€â”€ mcp_servers/                # Security tool servers
â”‚   â”‚   â”œâ”€â”€ semgrep_mcp/
â”‚   â”‚   â”œâ”€â”€ gitleaks_mcp/
â”‚   â”‚   â””â”€â”€ trivy_mcp/
â”‚   â””â”€â”€ shared/                     # Shared libraries
â”‚       â”œâ”€â”€ cognitive_kernel/       # Bedrock + Kendra integration
â”‚       â”œâ”€â”€ code_research/          # Deep code analysis
â”‚       â””â”€â”€ documentation/          # Wiki generation
â”œâ”€â”€ cli/
â”‚   â””â”€â”€ hivemind_cli/               # CLI tool
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ unit/                       # 109 unit tests
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ create-ecr-repos.sh         # Create ECR repositories
â”‚   â”œâ”€â”€ build-and-push-images.sh    # Build Docker images
â”‚   â””â”€â”€ validate-pre-deployment.sh  # Pre-flight checks
â”œâ”€â”€ DESIGN.md                        # Detailed architecture (1730 lines)
â”œâ”€â”€ SPEC.md                          # Technical specifications
â”œâ”€â”€ DEPLOYMENT.md                    # Deployment guide
â”œâ”€â”€ QUICK_START.md                   # Quick start guide
â””â”€â”€ README.md                        # This file
```

---

## ğŸ§ª Testing

### Run All Tests

```bash
# Run with coverage report
pytest tests/ -v --cov=src --cov-report=html --cov-report=term

# View HTML coverage report
open htmlcov/index.html
```

### Test Coverage

Current coverage: **76.69%** (target: 80%)

| Module | Coverage |
|--------|----------|
| Agents | 75-85% |
| Lambdas | 80-90% |
| MCP Servers | 85-95% |
| Shared Libraries | 70-80% |

### Test Structure

```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ test_archaeologist.py   # Context discovery tests
â”‚   â”‚   â”œâ”€â”€ test_strategist.py      # Planning tests
â”‚   â”‚   â”œâ”€â”€ test_coordinator.py     # Resource allocation tests
â”‚   â”‚   â”œâ”€â”€ test_synthesizer.py     # Finding generation tests
â”‚   â”‚   â”œâ”€â”€ test_critic.py          # Validation tests
â”‚   â”‚   â””â”€â”€ test_archivist.py       # Archival tests
â”‚   â”œâ”€â”€ lambdas/
â”‚   â”‚   â”œâ”€â”€ test_unpack.py          # Unpacking tests
â”‚   â”‚   â”œâ”€â”€ test_memory_ingestor.py # Memory formation tests
â”‚   â”‚   â””â”€â”€ test_failure_handler.py # Error handling tests
â”‚   â”œâ”€â”€ mcp_servers/
â”‚   â”‚   â”œâ”€â”€ test_semgrep_mcp.py     # Semgrep integration tests
â”‚   â”‚   â”œâ”€â”€ test_gitleaks_mcp.py    # Gitleaks integration tests
â”‚   â”‚   â””â”€â”€ test_trivy_mcp.py       # Trivy integration tests
â”‚   â””â”€â”€ shared/
â”‚       â”œâ”€â”€ test_bedrock_client.py  # Bedrock tests
â”‚       â”œâ”€â”€ test_deep_researcher.py # Research tests
â”‚       â””â”€â”€ test_wiki_generator.py  # Wiki generation tests
â””â”€â”€ conftest.py                     # Shared fixtures and mocks
```

---

## ğŸ’° Cost Estimation

### Monthly Cost Breakdown (Typical Usage: 100 scans/month)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Service                    Cost/Unit         Monthly Total â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Amazon Kendra (1 AZ)       $810/month        $810          â”‚
â”‚ Bedrock Claude Sonnet 4    $3/MTok input     $150-250      â”‚
â”‚ Bedrock Titan Embeddings   $0.10/1M tokens   $5-10         â”‚
â”‚ ECS Fargate (0.25 vCPU)    $0.04/hr/task     $50-100       â”‚
â”‚ Lambda Invocations         $0.20/1M          $5-10         â”‚
â”‚ S3 Storage (100GB)         $0.023/GB         $5-15         â”‚
â”‚ DynamoDB (on-demand)       $1.25/M writes    $10-20        â”‚
â”‚ ElastiCache (t3.micro)     $0.017/hr         $15-25        â”‚
â”‚ Data Transfer              $0.09/GB          $10-20        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL                                        $1,060-1,270  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cost Optimization Tips

1. **Use Kendra Developer Edition**: $1.40/hr when running vs. $810/month always-on
2. **Right-size Fargate**: Start with 0.25 vCPU, 0.5GB RAM per agent
3. **Enable S3 Lifecycle**: Move old artifacts to Glacier after 90 days
4. **Use DynamoDB On-Demand**: Only pay for actual usage
5. **Reserved Capacity**: If running 24/7, consider ElastiCache reserved instances

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [DESIGN.md](DESIGN.md) | Complete architectural design (1730 lines) |
| [SPEC.md](SPEC.md) | Technical specifications |
| [DEPLOYMENT.md](DEPLOYMENT.md) | Detailed deployment guide |
| [QUICK_START.md](QUICK_START.md) | Fast track deployment |
| [DEPLOYMENT_FIXES.md](DEPLOYMENT_FIXES.md) | Issues resolved before deployment |
| [TESTING.md](TESTING.md) | Testing strategy and coverage |

---

## ğŸ¤ Contributing

We welcome contributions! Areas for improvement:

- ğŸ§ª **Increase test coverage** to 80%+
- ğŸ”§ **Add MCP servers** for other security tools (Snyk, Bandit, etc.)
- ğŸ¤– **New agent types** (e.g., RemediationAgent for auto-fix suggestions)
- ğŸ“Š **Observability** - Add CloudWatch dashboards and X-Ray tracing
- ğŸŒ **Multi-region** - Support for cross-region deployments
- ğŸ“± **Web UI** - Dashboard for viewing findings and mission history

### Development Workflow

```bash
# 1. Create feature branch
git checkout -b feature/my-feature

# 2. Make changes and add tests
# ...

# 3. Run tests locally
pytest tests/ -v --cov=src

# 4. Commit with conventional commits
git commit -m "feat: add new MCP server for Bandit"

# 5. Push and create PR
git push origin feature/my-feature
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Amazon Bedrock** for Claude Sonnet 4 foundation models
- **Anthropic** for Claude AI
- **Model Context Protocol** for standardized tool integration
- **AWS CDK** for infrastructure as code
- **Open source security tools**: Semgrep, Gitleaks, Trivy

---

## ğŸ“ Support

- ğŸ› **Bug Reports**: [GitHub Issues](https://github.com/your-org/hivemind-prism/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/your-org/hivemind-prism/discussions)
- ğŸ“§ **Email**: support@your-org.com
- ğŸ“– **Wiki**: [Project Wiki](https://github.com/your-org/hivemind-prism/wiki)

---

## ğŸŒŸ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=your-org/hivemind-prism&type=Date)](https://star-history.com/#your-org/hivemind-prism&Date)

---

**Built with â¤ï¸ by the Hivemind-Prism Team**

*"Making security intelligence autonomous, intelligent, and adaptive."*